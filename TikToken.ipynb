{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae0c4288",
   "metadata": {},
   "source": [
    "## Install OpenAI Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209d57e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961a22ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b7f818",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2158021",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f325b4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import tiktoken\n",
    "from dotenv import dotenv_values\n",
    "config = dotenv_values(\".env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdb5fa4",
   "metadata": {},
   "source": [
    "## Add API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca316bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key  = config[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a840a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Declare Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1b2cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa166c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5745de",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_per_token = 0.002 / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6558f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n",
    "    \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        print(\"Warning: model not found. Using cl100k_base encoding.\")\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    if model == \"gpt-3.5-turbo\":\n",
    "        print(\"Warning: gpt-3.5-turbo may change over time. Returning num tokens assuming gpt-3.5-turbo-0301.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\")\n",
    "    elif model == \"gpt-4\":\n",
    "        print(\"Warning: gpt-4 may change over time. Returning num tokens assuming gpt-4-0314.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-4-0314\")\n",
    "    elif model == \"gpt-3.5-turbo-0301\":\n",
    "        tokens_per_message = 4  # every message follows <|start|>{role/name}\\n{content}<|end|>\\n\n",
    "        tokens_per_name = -1  # if there's a name, the role is omitted\n",
    "    elif model == \"gpt-4-0314\":\n",
    "        tokens_per_message = 3\n",
    "        tokens_per_name = 1\n",
    "    else:\n",
    "        raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not implemented for model {model}. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\")\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b188a4f5",
   "metadata": {},
   "source": [
    "## Insert Your Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99d0f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful, pattern-following assistant that translates corporate jargon into plain English.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"name\": \"example_user\",\n",
    "        \"content\": \"New synergies will help drive top-line growth.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"name\": \"example_assistant\",\n",
    "        \"content\": \"Things working well together will increase revenue.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"name\": \"example_user\",\n",
    "        \"content\": \"Let's circle back when we have more bandwidth to touch base on opportunities for increased leverage.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"name\": \"example_assistant\",\n",
    "        \"content\": \"Let's talk later when we're less busy about how to do better.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"This late pivot means we don't have time to boil the ocean for the client deliverable.\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febb7d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_text = \"\"\"\n",
    "It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\n",
    "\n",
    "However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered the rightful property of some one or other of their daughters.\n",
    "\n",
    "“My dear Mr. Bennet,” said his lady to him one day, “have you heard that Netherfield Park is let at last?”\n",
    "\n",
    "Mr. Bennet replied that he had not.\n",
    "\n",
    "“But it is,” returned she; “for Mrs. Long has just been here, and she told me all about it.”\n",
    "\n",
    "Mr. Bennet made no answer.\n",
    "\n",
    "“Do you not want to know who has taken it?” cried his wife impatiently.\n",
    "\n",
    "“YOU want to tell me, and I have no objection to hearing it.”\n",
    "\n",
    "This was invitation enough.\n",
    "\n",
    "“Why, my dear, you must know, Mrs. Long says that Netherfield is taken by a young man of large fortune from the north of England; that he came down on Monday in a chaise and four to see the place, and was so much delighted with it, that he agreed with Mr. Morris immediately; that he is to take possession before Michaelmas, and some of his servants are to be in the house by the end of next week.”\n",
    "\n",
    "“What is his name?”\n",
    "\n",
    "“Bingley.”\n",
    "\n",
    "“Is he married or single?”\n",
    "\n",
    "“Oh! Single, my dear, to be sure! A single man of large fortune; four or five thousand a year. What a fine thing for our girls!”\n",
    "\n",
    "“How so? How can it affect them?”\n",
    "\n",
    "“My dear Mr. Bennet,” replied his wife, “how can you be so tiresome! You must know that I am thinking of his marrying one of them.”\n",
    "\n",
    "“Is that his design in settling here?”\n",
    "\n",
    "“Design! Nonsense, how can you talk so! But it is very likely that he MAY fall in love with one of them, and therefore you must visit him as soon as he comes.”\n",
    "\n",
    "“I see no occasion for that. You and the girls may go, or you may send them by themselves, which perhaps will be still better, for as you are as handsome as any of them, Mr. Bingley may like you the best of the party.”\n",
    "\n",
    "“My dear, you flatter me. I certainly HAVE had my share of beauty, but I do not pretend to be anything extraordinary now. When a woman has five grown-up daughters, she ought to give over thinking of her own beauty.”\n",
    "\n",
    "“In such cases, a woman has not often much beauty to think of.”\n",
    "\n",
    "“But, my dear, you must indeed go and see Mr. Bingley when he comes into the neighbourhood.”\n",
    "\n",
    "“It is more than I engage for, I assure you.”\n",
    "\n",
    "“But consider your daughters. Only think what an establishment it would be for one of them. Sir William and Lady Lucas are determined to go, merely on that account, for in general, you know, they visit no newcomers. Indeed you must go, for it will be impossible for US to visit him if you do not.”\n",
    "\n",
    "“You are over-scrupulous, surely. I dare say Mr. Bingley will be very glad to see you; and I will send a few lines by you to assure him of my hearty consent to his marrying whichever he chooses of the girls; though I must throw in a good word for my little Lizzy.”\n",
    "\n",
    "“I desire you will do no such thing. Lizzy is not a bit better than the others; and I am sure she is not half so handsome as Jane, nor half so good-humoured as Lydia. But you are always giving HER the preference.”\n",
    "\n",
    "“They have none of them much to recommend them,” replied he; “they are all silly and ignorant like other girls; but Lizzy has something more of quickness than her sisters.”\n",
    "\n",
    "“Mr. Bennet, how CAN you abuse your own children in such a way? You take delight in vexing me. You have no compassion for my poor nerves.”\n",
    "\n",
    "“You mistake me, my dear. I have a high respect for your nerves. They are my old friends. I have heard you mention them with consideration these last twenty years at least.”\n",
    "\n",
    "Mr. Bennet was so odd a mixture of quick parts, sarcastic humour, reserve, and caprice, that the experience of three-and-twenty years had been insufficient to make his wife understand his character. HER mind was less difficult to develop. She was a woman of mean understanding, little information, and uncertain temper. When she was discontented, she fancied herself nervous. The business of her life was to get her daughters married; its solace was visiting and news.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33cfd23",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23585944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt():\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"give my 3 joke stories\"\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=256,\n",
    "        temperature=0.7,\n",
    "        top_p=0.5,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    print(completion.choices[0][\"message\"][\"content\"])\n",
    "    print(\"-----\")\n",
    "    print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27fdc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Execute Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d82bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(enc.encode(book_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03cb7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = num_tokens_from_string(book_text, \"gpt-3.5-turbo\")\n",
    "print(tokens)\n",
    "print(f\"${tokens * price_per_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816f1293",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens_from_messages(example_messages, \"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078280f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens_from_messages(example_messages, \"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af966fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_prompt()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
